{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pJr2QX16y0C"
      },
      "source": [
        "# **Préparer les données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI65qFkLjyEY"
      },
      "source": [
        "### **Monter le dossier dans Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVb5j_uZDvRs",
        "outputId": "ce5c390e-7e42-4b1f-cb38-f45612af338d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DcknGEsEkrE"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Projet_HMIN339M')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEIWGiCq_s3g"
      },
      "source": [
        "### **Importation de quelques librairies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HzSSHr5ooul"
      },
      "source": [
        "import numpy as np\n",
        "import tifffile\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVrWVyvfkBDD"
      },
      "source": [
        "### **Lecture de la série temporelle d'images et Normalisation par bande sur la série temporelle entre 0 et 1** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95CB2_IllQFu"
      },
      "source": [
        "#### **Lecture des images et création des séries temporelles de bandes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut67k4u3Vezu",
        "outputId": "023a9380-37e4-43ee-aea9-048a74897819"
      },
      "source": [
        "# Récupérer la liste des images\n",
        "lst_img = glob.glob ('Images/*.tif')\n",
        "lst_img.sort() # ordonner par date si ce n'est pas le cas\n",
        "lst_img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Images/20160322_S2A.tif',\n",
              " 'Images/20160710_S2A.tif',\n",
              " 'Images/20160730_S2A.tif',\n",
              " 'Images/20160928_S2A.tif',\n",
              " 'Images/20161018_S2A.tif',\n",
              " 'Images/20161127_S2A.tif',\n",
              " 'Images/20161217_S2A.tif',\n",
              " 'Images/20161227_S2A.tif']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSpMjDMNa-Bg",
        "outputId": "c629cacb-6e28-48e6-ff1a-223651186d01"
      },
      "source": [
        "# Lecture de la bande du rouge (B1) pour toute la série temporelle\n",
        "red_ts = []\n",
        "for img in lst_img:\n",
        "  red_ts.append( tifffile.imread(img)[:,:,0]) # Rouge\n",
        "red_ts = np.dstack(red_ts)\n",
        "red_ts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5412, 5592, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X97WsP3kcTL1",
        "outputId": "212395ed-1dd8-451d-e385-b5b864f35849"
      },
      "source": [
        "# Lecture de la bande du vert (B2) pour toute la série temporelle\n",
        "green_ts = []\n",
        "for img in lst_img:\n",
        "  green_ts.append( tifffile.imread(img)[:,:,1]) # Vert\n",
        "green_ts = np.dstack(green_ts)\n",
        "green_ts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5412, 5592, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1GBdVCGcbcK",
        "outputId": "5b0e15f6-de7b-4f35-d2c1-f905bb2e15ac"
      },
      "source": [
        "# Lecture de la bande du bleu (B3) pour toute la série temporelle\n",
        "blue_ts = []\n",
        "for img in lst_img:\n",
        "  blue_ts.append( tifffile.imread(img)[:,:,2]) # Bleu\n",
        "blue_ts = np.dstack(blue_ts)\n",
        "blue_ts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5412, 5592, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDd4BjV-cbz8",
        "outputId": "115b7a9b-602b-40dc-e345-c755f96afae3"
      },
      "source": [
        "# Lecture de la bande du proche infrarouge (B4) pour toute la série temporelle\n",
        "nir_ts = []\n",
        "for img in lst_img:\n",
        "  nir_ts.append( tifffile.imread(img)[:,:,3]) # Proche infra rouge\n",
        "nir_ts = np.dstack(nir_ts)\n",
        "nir_ts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5412, 5592, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJVBYJxuuJDA",
        "outputId": "d66ed901-b145-490c-c0f3-e5c44bca709a"
      },
      "source": [
        "# Calculer des indices spectraux comme le NDVI\n",
        "ndvi_ts = np.where(nir_ts + red_ts == 0, 0, (nir_ts - red_ts) / (nir_ts + red_ts)).astype(np.float32)\n",
        "ndvi_ts.shape, ndvi_ts.dtype, ndvi_ts.min(), ndvi_ts.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5412, 5592, 8), dtype('float32'), -0.9994976, 0.99976385)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOOWsKQHlHvS"
      },
      "source": [
        "#### **Normalisation en utilisant le min et le max des bandes sur les séries temporelles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoOk5-UccvSe",
        "outputId": "bfccc99e-b11a-49c5-84d2-0922d18c0679"
      },
      "source": [
        "# Normalisation des séries temporelles par bande: Rouge\n",
        "red_ts_norm = ( red_ts - red_ts.min() ) / ( red_ts.max() - red_ts.min() ).astype(np.float32)\n",
        "red_ts_norm.min() , red_ts_norm.max(), red_ts_norm.shape, red_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c1DlhJTe_6h",
        "outputId": "e1050511-e489-4ae4-eed7-24a0f94c5992"
      },
      "source": [
        "# Normalisation des séries temporelles par bande: Vert\n",
        "green_ts_norm = ( green_ts - green_ts.min() ) / ( green_ts.max() - green_ts.min() ).astype(np.float32)\n",
        "green_ts = None\n",
        "green_ts_norm.min() , green_ts_norm.max(), green_ts_norm.shape, green_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFNAbyIyfAJT",
        "outputId": "7de70a1f-d537-4e94-9bd3-be36a4527f51"
      },
      "source": [
        "# Normalisation des séries temporelles par bande: Bleu\n",
        "blue_ts_norm = ( blue_ts - blue_ts.min() ) / ( blue_ts.max() - blue_ts.min() ).astype(np.float32)\n",
        "blue_ts = None\n",
        "blue_ts_norm.min() , blue_ts_norm.max(), blue_ts_norm.shape, blue_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epIhb6brfAUK",
        "outputId": "126d2797-1088-44db-aa23-f3593b5fda5e"
      },
      "source": [
        "# Normalisation des séries temporelles par bande: Proche infrarouge\n",
        "nir_ts_norm = ( nir_ts - nir_ts.min() ) / ( nir_ts.max() - nir_ts.min() ).astype(np.float32)\n",
        "nir_ts_norm.min() , nir_ts_norm.max(), nir_ts_norm.shape, nir_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAtrTnz_uQ2Y",
        "outputId": "928c49b8-0546-4a23-9ee3-eb6d579c8980"
      },
      "source": [
        "# Normaliser les indices spectraux que vous aurez calculé\n",
        "ndvi_ts_norm = ( ndvi_ts - ndvi_ts.min() ) / ( ndvi_ts.max() - ndvi_ts.min( )).astype(np.float32)\n",
        "ndvi_ts_norm.min(), ndvi_ts_norm.max(), ndvi_ts_norm.shape, ndvi_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDQUbh3Nkpn7"
      },
      "source": [
        "### **Lecture de la vérité terrain et récupération des positions des pixels du jeu d'entraînement et de test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_mXEBEKmuw7"
      },
      "source": [
        "#### **Lecture des fichiers de la vérité terrain**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBCQhbMUoBJU",
        "outputId": "00f67c14-b1dd-4f13-b47d-6c41f5b6d7af"
      },
      "source": [
        "# Lire le fichier correspondant aux classes d'occupation du sol\n",
        "gt_class = tifffile.imread ('Verite_terrain/DORDOGNE_VT_CLASS.tif')\n",
        "gt_class.shape , gt_class.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5412, 5592), dtype('uint8'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLnTil_psMLW",
        "outputId": "be6401ab-17e6-4717-8459-a3b1834038c7"
      },
      "source": [
        "# Lire le fichier correspondant aux identifiants\n",
        "gt_id = tifffile.imread ('Verite_terrain/DORDOGNE_VT_ID.tif')\n",
        "gt_id.shape, gt_id.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5412, 5592), dtype('int16'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjyGTdRpm5ii"
      },
      "source": [
        "#### **Récupération des positions des pixels d'entraînement et de test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yosWk1_BgiLE"
      },
      "source": [
        "# Récupérer les positions des échantillons d'entraînement et test\n",
        "idx_train_ = np.where ( (gt_id!=0) & (gt_class!=0) )\n",
        "idx_test = np.where ( (gt_id!=0) & (gt_class==0) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uRX0xj4zjvVY",
        "outputId": "29ae1109-3bcd-4147-de9c-9a89c438853b"
      },
      "source": [
        "# Lecture des identifiants et labels des échantillons d'entraînement\n",
        "train_id_ = gt_id[idx_train_]\n",
        "train_y_ = gt_class[idx_train_]\n",
        "f'échantillons d\\'entrainement: {train_y_.shape[0]} pixels, {len(np.unique(train_id_))} objets'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"échantillons d'entrainement: 605431 pixels, 1859 objets\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kiPCaHQ2jtZu",
        "outputId": "399ede34-fade-48f9-a065-bf48528b9bd1"
      },
      "source": [
        "# Lecture des identifiants et labels des échantillons de test\n",
        "test_id = gt_id[idx_test]\n",
        "f'échantillons test: {test_id.shape[0]} pixels, {len(np.unique(test_id))} objets'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'échantillons test: 207485 pixels, 800 objets'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNFyNkc5oc6z"
      },
      "source": [
        "### **Création d'un jeu de validation en prenant une partie du jeu d'entraînement**\n",
        "Pour cela, on s'assure de faire la division en mettant les pixels ayant le même identifiant dans un seul et même lot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2hI-jAEqrac1",
        "outputId": "8b0cb4a6-0495-4e85-f357-5c37660a084a"
      },
      "source": [
        "# Dataframe pour créer un jeu de validation\n",
        "samples = pd.DataFrame({'ID':train_id_,'Class':train_y_})\n",
        "samples = samples.drop_duplicates(keep='first')\n",
        "samples.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>422</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2677</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>201</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>423</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>496</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  Class\n",
              "0     422      2\n",
              "4    2677      5\n",
              "5     201      3\n",
              "29    423      2\n",
              "100   496      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "894SPjgRs_S7",
        "outputId": "1f9189f3-31dd-4fae-ca71-10362fb5e81f"
      },
      "source": [
        "# 30% des échantillons de chaque classe affecté au jeu de validation\n",
        "train_id = []\n",
        "valid_id = []\n",
        "for c in np.unique(samples.Class.values) :\n",
        "    samples_c = samples.loc[samples.Class==c]\n",
        "    samples_frac = samples_c.sample(frac=0.7,random_state=1234) \n",
        "    train_id.extend( samples_frac.ID.values )\n",
        "    valid_id.extend( samples_c.drop(samples_frac.index).ID.values )\n",
        "len(train_id),len(valid_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1301, 558)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J609q3BrKRk"
      },
      "source": [
        "### **Récupération des positions des nouveaux échantillons d'entraînement et de validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmVBWpvFdjlk"
      },
      "source": [
        "# Récupérer les positions des nouveaux échantillons d'entraînement et validation\n",
        "idx_train = np.where ( np.isin(gt_id,train_id) )\n",
        "idx_valid = np.where ( np.isin(gt_id,valid_id) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U6m2R-UwEFK"
      },
      "source": [
        "### **Lire finalement les labels correspondant aux nouveaux échantillons d'entraînement, de validation et test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF_PEzn3vQzT",
        "outputId": "28f7eebe-341a-4ef4-bd9b-f9ddff6f57d4"
      },
      "source": [
        "train_y = gt_class[idx_train]\n",
        "valid_y = gt_class[idx_valid]\n",
        "test_y = gt_class[idx_test]\n",
        "train_y.shape, valid_y.shape, test_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((451962,), (153469,), (207485,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAt4KCeZR1Os"
      },
      "source": [
        "### **Lire finalement les identifiants correspondant aux nouveaux échantillons d'entraînement, de validation et test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3SiC0eVRvtA",
        "outputId": "9b836fb4-e2f3-4ceb-823a-39b79131cadd"
      },
      "source": [
        "# utile pour les aggrégations au niveau objet\n",
        "# train_id_array = gt_id[idx_train] # Pas vraiment nécessaire pour les échantillons d'entraînements\n",
        "valid_id_array = gt_id[idx_valid]\n",
        "test_id_array = gt_id[idx_test]\n",
        "#train_id_array.shape, \n",
        "valid_id_array.shape, test_id_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((153469,), (207485,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-8J5r9r3KI"
      },
      "source": [
        "### **Lire finalement les valeurs des séries temporelles correspondant aux nouveaux échantillons d'entraînement, de validation et test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXS90K1Vsg4H"
      },
      "source": [
        "#### **Pour un Perceptron multi-couche**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwjGd9exkFia",
        "outputId": "6160e956-7c52-4a81-99f9-f07b032370b1"
      },
      "source": [
        "# Un perceptron multi-couche ou un algo classique de machine learning requiert un tableau 2D du type \n",
        "# (nombre d'échantillons, nombre de features=(nombre de dates x nombre de bandes))\n",
        "# Vous pouvez rajouter au stack les indices spectraux normalisés que vous aurez calculé\n",
        "\n",
        "train_X = np.column_stack ( ( blue_ts_norm[idx_train], green_ts_norm[idx_train], red_ts_norm[idx_train], nir_ts_norm[idx_train] ) )\n",
        "\n",
        "valid_X = np.column_stack ( ( blue_ts_norm[idx_valid], green_ts_norm[idx_valid], red_ts_norm[idx_valid], nir_ts_norm[idx_valid] ) )\n",
        "\n",
        "test_X = np.column_stack ( ( blue_ts_norm[idx_test], green_ts_norm[idx_test], red_ts_norm[idx_test], nir_ts_norm[idx_test] ) )\n",
        "\n",
        "train_X.shape, valid_X.shape, test_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((451962, 32), (153469, 32), (207485, 32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiqM_sYRt5IL"
      },
      "source": [
        "### **Sauvegarde des données d'entraînement, de validation et test en fichier numpy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPiv0fo3uJ8s"
      },
      "source": [
        "# Ainsi de cette façon vous pourrez continuer directement avec la création des modèles et en libérant la mémoire de tout ce qui a été fait précédemment\n",
        "Path('data').mkdir(exist_ok=True, parents=True)\n",
        "np.save('data/MLP/train_X.npy',train_X)\n",
        "np.save('data/MLP/train_y.npy',train_y)\n",
        "# np.save('data/train_id.npy',train_id_array)\n",
        "\n",
        "np.save('data/MLP/valid_X.npy',valid_X)\n",
        "np.save('data/MLP/valid_y.npy',valid_y)\n",
        "np.save('data/MLP/valid_id.npy',valid_id_array)\n",
        "\n",
        "np.save('data/MLP/test_X.npy',test_X)\n",
        "np.save('data/MLP/test_id.npy',test_id_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOM6_mv--8IX"
      },
      "source": [
        "Videz la mémoire en redémarrant l'environnement d'exécution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv0jts6w6nxr"
      },
      "source": [
        "# **Votre modèle de deep learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmBRjg3QFrLe"
      },
      "source": [
        "### **Remontage de Drive et Importation de quelques librairies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJUrD-aVMaN0",
        "outputId": "891d50e6-95c6-47f3-c4d5-c87450ea09e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K5Xk6WeALcH"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Projet_HMIN339M')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tifffile\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Concatenate, Dense, Dropout, Activation, Flatten, Conv2D, Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D, BatchNormalization, Flatten, GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlRFSn7f_yKx"
      },
      "source": [
        "### **Recharger les données d'entraînement, de validation et test en fichier numpy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVzkEkQA-jM7",
        "outputId": "38370190-a140-4166-ca55-0e5e1446280a"
      },
      "source": [
        "# Recharger les données après avoir vidé la mémoire\n",
        "train_X = np.load('data/MLP/train_X.npy')\n",
        "train_y = np.load('data/MLP/train_y.npy')\n",
        "\n",
        "valid_X = np.load('data/MLP/valid_X.npy')\n",
        "valid_y = np.load('data/MLP/valid_y.npy')\n",
        "valid_id = np.load('data/MLP/valid_id.npy')\n",
        "\n",
        "test_X = np.load('data/MLP/test_X.npy')\n",
        "test_id = np.load('data/MLP/test_id.npy')\n",
        "train_X.shape, train_y.shape, valid_X.shape, valid_y.shape, valid_id.shape, test_X.shape, test_id.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((451962, 32),\n",
              " (451962,),\n",
              " (153469, 32),\n",
              " (153469,),\n",
              " (153469,),\n",
              " (207485, 32),\n",
              " (207485,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K23T_c-EAj_z"
      },
      "source": [
        "### **Encoder les labels entre 0 et 4 de sorte à matcher les prédictions des réseaux de neurones**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY74aok1Arfi",
        "outputId": "8e201039-b334-4470-bc0b-479fab334cc4"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_y)\n",
        "train_y_enc = encoder.transform(train_y)\n",
        "valid_y_enc = encoder.transform(valid_y)\n",
        "np.unique(train_y), np.unique(train_y_enc), np.unique(valid_y), np.unique(valid_y_enc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 3, 4, 5], dtype=uint8),\n",
              " array([0, 1, 2, 3, 4]),\n",
              " array([1, 2, 3, 4, 5], dtype=uint8),\n",
              " array([0, 1, 2, 3, 4]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpH3oJPVE3uE"
      },
      "source": [
        "### **Définition séquentielle de votre modèle avec Keras**\n",
        "\n",
        "N'oubliez pas de spécifier l'input shape qui varie en fonction des types d'architectures, le nombre de neurones de la couche de sortie qui équivaut au nombre de classes que vous avez et de l'activer avec une fonction Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvUdNqlKAu0X"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=(32)),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "  tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhhSzQvSFALk",
        "outputId": "a404cc84-92d9-4a39-e0a5-01a00683b2b5"
      },
      "source": [
        "# Afficher votre modèle\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 256)               8448      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 75,525\n",
            "Trainable params: 75,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxtoXsFgPNX7",
        "outputId": "de5fd0d5-3c7d-4c2f-942d-2ef898831eff"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 256)               8448      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 75,525\n",
            "Trainable params: 75,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "_cGHVPi2Pi5H",
        "outputId": "416f8b1f-4424-44d9-91a1-56d1239abfe2"
      },
      "source": [
        "tf.keras.utils.plot_model(model,show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2ksSpJGF1gP"
      },
      "source": [
        "### **Compiler votre modèle en définissant une fonction de côut, un optmiseur et une métrique**\n",
        "\n",
        "Dans le cas d'une classification multi-classe, votre fonction de coût est la cross entropy catégorique. $Adam$ est un bon optimiseur de départ pour vos projets. Ici vous pouvez surveiller la métrique $Accuracy$. Pour la fonction de coût (loss), je n'utilse pas l'argument $from\\_logits=True$ car j'ai déjà activé la couche de sortie avec une fonction Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtwtaGndG7UN"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4) ,loss=tf.keras.losses.SparseCategoricalCrossentropy(),loss_weights=[1,.5,.5], metrics=tf.keras.metrics.SparseCategoricalAccuracy(name='acc'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLKCHopeIIet"
      },
      "source": [
        "### **Définir un callback pour sauver les poids de votre modèle sur les meilleures époque c'est à dire les moments où il s'améliorera sur le jeu de validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-_N87DhIH5N"
      },
      "source": [
        "Path('my_model').mkdir(exist_ok=True, parents=True)\n",
        "checkpointpath = os.path.join('my_model','model') # chemin où sauver le modèle\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(\n",
        "              checkpointpath,\n",
        "              verbose=1, # niveau de log\n",
        "              monitor='val_main_acc', # nom de la métrique à surveiller\n",
        "              save_best_only=True, # sauver uniquement le meilleur modèle\n",
        "              save_weights_only=True)] # sauver uniquement les poids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozHZJ2CZH72X"
      },
      "source": [
        "### **Entraîner votre modèle pour un certain nombre d'époques**\n",
        "\n",
        "Le paramètre $validation\\_data$ vous permet de spécifier des données de validation et de votre le comportement de votre modèle sur un jeu indépendant dont il n'a pas la connaissance. \n",
        "\n",
        "La taille de batch ($batch\\_size$) correspond au nombre d'échantillons sur lesquels le modèle est entraîné à la fois sur une époque. Vous pouvez le mettre à (ex. 32, 64, 128, 256) et plus il est grand ce qui requiert d'avoir de la mémoire plus le temps d'exécution d'une époque sera court\n",
        "\n",
        "J'utilise les labels encodés entre 0 et 4 car la prédiction sur les distributions de probabilités du modèle est retournée avec un argmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WpxHz3FJuJ6",
        "outputId": "8809bf38-6fc6-470c-bd84-1bd3259313a7"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "EPOCHS = 100\n",
        "hist = model.fit (train_X, train_y_enc, validation_data=(valid_X,valid_y_enc), batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1762/1766 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9259WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2128 - acc: 0.9259 - val_loss: 0.2634 - val_acc: 0.9030\n",
            "Epoch 2/100\n",
            "1750/1766 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9260WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2115 - acc: 0.9260 - val_loss: 0.2647 - val_acc: 0.9045\n",
            "Epoch 3/100\n",
            "1750/1766 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9264WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2107 - acc: 0.9264 - val_loss: 0.2820 - val_acc: 0.8974\n",
            "Epoch 4/100\n",
            "1762/1766 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9269WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.2098 - acc: 0.9269 - val_loss: 0.2721 - val_acc: 0.9004\n",
            "Epoch 5/100\n",
            "1765/1766 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9272WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2084 - acc: 0.9272 - val_loss: 0.2773 - val_acc: 0.8996\n",
            "Epoch 6/100\n",
            "1758/1766 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9271WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2080 - acc: 0.9271 - val_loss: 0.2810 - val_acc: 0.8981\n",
            "Epoch 7/100\n",
            "1745/1766 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9276WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.2069 - acc: 0.9276 - val_loss: 0.2675 - val_acc: 0.9034\n",
            "Epoch 8/100\n",
            "1751/1766 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9278WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2062 - acc: 0.9278 - val_loss: 0.2812 - val_acc: 0.8991\n",
            "Epoch 9/100\n",
            "1749/1766 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9282WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2051 - acc: 0.9283 - val_loss: 0.2699 - val_acc: 0.9009\n",
            "Epoch 10/100\n",
            "1743/1766 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9283WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2043 - acc: 0.9284 - val_loss: 0.2812 - val_acc: 0.8972\n",
            "Epoch 11/100\n",
            "1743/1766 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9288WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2032 - acc: 0.9288 - val_loss: 0.2859 - val_acc: 0.8983\n",
            "Epoch 12/100\n",
            "1762/1766 [============================>.] - ETA: 0s - loss: 0.2025 - acc: 0.9290WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2025 - acc: 0.9290 - val_loss: 0.2820 - val_acc: 0.8992\n",
            "Epoch 13/100\n",
            "1761/1766 [============================>.] - ETA: 0s - loss: 0.2019 - acc: 0.9292WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2019 - acc: 0.9292 - val_loss: 0.2742 - val_acc: 0.9015\n",
            "Epoch 14/100\n",
            "1759/1766 [============================>.] - ETA: 0s - loss: 0.2009 - acc: 0.9294WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2009 - acc: 0.9294 - val_loss: 0.2662 - val_acc: 0.9030\n",
            "Epoch 15/100\n",
            "1765/1766 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9297WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.2002 - acc: 0.9297 - val_loss: 0.2812 - val_acc: 0.8990\n",
            "Epoch 16/100\n",
            "1759/1766 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9301WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1995 - acc: 0.9301 - val_loss: 0.2834 - val_acc: 0.8991\n",
            "Epoch 17/100\n",
            "1745/1766 [============================>.] - ETA: 0s - loss: 0.1988 - acc: 0.9300WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1986 - acc: 0.9301 - val_loss: 0.2671 - val_acc: 0.9037\n",
            "Epoch 18/100\n",
            "1765/1766 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9305WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1978 - acc: 0.9305 - val_loss: 0.2694 - val_acc: 0.9038\n",
            "Epoch 19/100\n",
            "1745/1766 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9307WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1967 - acc: 0.9307 - val_loss: 0.2775 - val_acc: 0.9007\n",
            "Epoch 20/100\n",
            "1744/1766 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9310WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1960 - acc: 0.9310 - val_loss: 0.2701 - val_acc: 0.9035\n",
            "Epoch 21/100\n",
            "1753/1766 [============================>.] - ETA: 0s - loss: 0.1953 - acc: 0.9313WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1955 - acc: 0.9312 - val_loss: 0.2783 - val_acc: 0.8998\n",
            "Epoch 22/100\n",
            "1763/1766 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9316WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1945 - acc: 0.9316 - val_loss: 0.2751 - val_acc: 0.9012\n",
            "Epoch 23/100\n",
            "1764/1766 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9319WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1935 - acc: 0.9319 - val_loss: 0.2734 - val_acc: 0.9008\n",
            "Epoch 24/100\n",
            "1746/1766 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9318WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1933 - acc: 0.9319 - val_loss: 0.2730 - val_acc: 0.9031\n",
            "Epoch 25/100\n",
            "1754/1766 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9320WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1925 - acc: 0.9320 - val_loss: 0.2814 - val_acc: 0.8978\n",
            "Epoch 26/100\n",
            "1762/1766 [============================>.] - ETA: 0s - loss: 0.1917 - acc: 0.9326WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1917 - acc: 0.9326 - val_loss: 0.2790 - val_acc: 0.9009\n",
            "Epoch 27/100\n",
            "1760/1766 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9324WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1909 - acc: 0.9324 - val_loss: 0.2790 - val_acc: 0.9022\n",
            "Epoch 28/100\n",
            "1748/1766 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9330WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1903 - acc: 0.9330 - val_loss: 0.2793 - val_acc: 0.9001\n",
            "Epoch 29/100\n",
            "1758/1766 [============================>.] - ETA: 0s - loss: 0.1897 - acc: 0.9331WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1898 - acc: 0.9331 - val_loss: 0.2771 - val_acc: 0.9000\n",
            "Epoch 30/100\n",
            "1749/1766 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9336WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1885 - acc: 0.9336 - val_loss: 0.2875 - val_acc: 0.8951\n",
            "Epoch 31/100\n",
            "1753/1766 [============================>.] - ETA: 0s - loss: 0.1879 - acc: 0.9340WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1878 - acc: 0.9340 - val_loss: 0.2842 - val_acc: 0.8999\n",
            "Epoch 32/100\n",
            "1752/1766 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9340WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1872 - acc: 0.9339 - val_loss: 0.2773 - val_acc: 0.9019\n",
            "Epoch 33/100\n",
            "1766/1766 [==============================] - ETA: 0s - loss: 0.1869 - acc: 0.9341WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1869 - acc: 0.9341 - val_loss: 0.2740 - val_acc: 0.9035\n",
            "Epoch 34/100\n",
            "1750/1766 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9343WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1859 - acc: 0.9343 - val_loss: 0.2938 - val_acc: 0.8979\n",
            "Epoch 35/100\n",
            "1756/1766 [============================>.] - ETA: 0s - loss: 0.1852 - acc: 0.9346WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1852 - acc: 0.9346 - val_loss: 0.2809 - val_acc: 0.8980\n",
            "Epoch 36/100\n",
            "1761/1766 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9347WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1846 - acc: 0.9347 - val_loss: 0.2852 - val_acc: 0.8998\n",
            "Epoch 37/100\n",
            "1743/1766 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9351WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1837 - acc: 0.9351 - val_loss: 0.2857 - val_acc: 0.9003\n",
            "Epoch 38/100\n",
            "1760/1766 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9352WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1831 - acc: 0.9352 - val_loss: 0.2882 - val_acc: 0.8979\n",
            "Epoch 39/100\n",
            "1754/1766 [============================>.] - ETA: 0s - loss: 0.1822 - acc: 0.9357WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1822 - acc: 0.9357 - val_loss: 0.2973 - val_acc: 0.8977\n",
            "Epoch 40/100\n",
            "1745/1766 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9356WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1815 - acc: 0.9357 - val_loss: 0.2907 - val_acc: 0.8985\n",
            "Epoch 41/100\n",
            "1766/1766 [==============================] - ETA: 0s - loss: 0.1811 - acc: 0.9360WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1811 - acc: 0.9360 - val_loss: 0.2843 - val_acc: 0.9011\n",
            "Epoch 42/100\n",
            "1757/1766 [============================>.] - ETA: 0s - loss: 0.1803 - acc: 0.9359WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1803 - acc: 0.9360 - val_loss: 0.2891 - val_acc: 0.8966\n",
            "Epoch 43/100\n",
            "1753/1766 [============================>.] - ETA: 0s - loss: 0.1797 - acc: 0.9363WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1797 - acc: 0.9363 - val_loss: 0.2875 - val_acc: 0.8989\n",
            "Epoch 44/100\n",
            "1759/1766 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9366WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1793 - acc: 0.9366 - val_loss: 0.2835 - val_acc: 0.9010\n",
            "Epoch 45/100\n",
            "1756/1766 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9366WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1785 - acc: 0.9366 - val_loss: 0.2888 - val_acc: 0.8979\n",
            "Epoch 46/100\n",
            "1751/1766 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9368WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1782 - acc: 0.9367 - val_loss: 0.2828 - val_acc: 0.8994\n",
            "Epoch 47/100\n",
            "1751/1766 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9373WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1774 - acc: 0.9373 - val_loss: 0.2976 - val_acc: 0.8945\n",
            "Epoch 48/100\n",
            "1753/1766 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9373WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1767 - acc: 0.9374 - val_loss: 0.2963 - val_acc: 0.8969\n",
            "Epoch 49/100\n",
            "1761/1766 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.9376WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1761 - acc: 0.9376 - val_loss: 0.2853 - val_acc: 0.9006\n",
            "Epoch 50/100\n",
            "1759/1766 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9382WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1753 - acc: 0.9382 - val_loss: 0.2808 - val_acc: 0.9001\n",
            "Epoch 51/100\n",
            "1757/1766 [============================>.] - ETA: 0s - loss: 0.1749 - acc: 0.9382WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1749 - acc: 0.9382 - val_loss: 0.2867 - val_acc: 0.8979\n",
            "Epoch 52/100\n",
            "1757/1766 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9381WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1743 - acc: 0.9381 - val_loss: 0.2872 - val_acc: 0.9005\n",
            "Epoch 53/100\n",
            "1744/1766 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9386WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1738 - acc: 0.9386 - val_loss: 0.2968 - val_acc: 0.8984\n",
            "Epoch 54/100\n",
            "1742/1766 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9389WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1728 - acc: 0.9389 - val_loss: 0.3023 - val_acc: 0.8962\n",
            "Epoch 55/100\n",
            "1757/1766 [============================>.] - ETA: 0s - loss: 0.1723 - acc: 0.9391WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1723 - acc: 0.9391 - val_loss: 0.2814 - val_acc: 0.9010\n",
            "Epoch 56/100\n",
            "1753/1766 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9393WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1715 - acc: 0.9393 - val_loss: 0.2791 - val_acc: 0.9012\n",
            "Epoch 57/100\n",
            "1751/1766 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9392WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1715 - acc: 0.9392 - val_loss: 0.2975 - val_acc: 0.8957\n",
            "Epoch 58/100\n",
            "1765/1766 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9395WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1707 - acc: 0.9395 - val_loss: 0.2771 - val_acc: 0.9033\n",
            "Epoch 59/100\n",
            "1764/1766 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9396WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1703 - acc: 0.9396 - val_loss: 0.2865 - val_acc: 0.9005\n",
            "Epoch 60/100\n",
            "1754/1766 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9400WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1696 - acc: 0.9400 - val_loss: 0.3003 - val_acc: 0.8967\n",
            "Epoch 61/100\n",
            "1748/1766 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9399WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1691 - acc: 0.9398 - val_loss: 0.2810 - val_acc: 0.9015\n",
            "Epoch 62/100\n",
            "1756/1766 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9406WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1684 - acc: 0.9405 - val_loss: 0.2859 - val_acc: 0.9007\n",
            "Epoch 63/100\n",
            "1756/1766 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9405WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1678 - acc: 0.9405 - val_loss: 0.2967 - val_acc: 0.8961\n",
            "Epoch 64/100\n",
            "1746/1766 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9410WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1673 - acc: 0.9410 - val_loss: 0.3009 - val_acc: 0.8943\n",
            "Epoch 65/100\n",
            "1757/1766 [============================>.] - ETA: 0s - loss: 0.1669 - acc: 0.9408WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1669 - acc: 0.9408 - val_loss: 0.2874 - val_acc: 0.8993\n",
            "Epoch 66/100\n",
            "1766/1766 [==============================] - ETA: 0s - loss: 0.1663 - acc: 0.9413WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1663 - acc: 0.9413 - val_loss: 0.2969 - val_acc: 0.8962\n",
            "Epoch 67/100\n",
            "1766/1766 [==============================] - ETA: 0s - loss: 0.1661 - acc: 0.9413WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1661 - acc: 0.9413 - val_loss: 0.3190 - val_acc: 0.8919\n",
            "Epoch 68/100\n",
            "1761/1766 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9413WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1654 - acc: 0.9413 - val_loss: 0.2964 - val_acc: 0.8996\n",
            "Epoch 69/100\n",
            "1757/1766 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9418WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1650 - acc: 0.9418 - val_loss: 0.2820 - val_acc: 0.9017\n",
            "Epoch 70/100\n",
            "1765/1766 [============================>.] - ETA: 0s - loss: 0.1645 - acc: 0.9418WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1645 - acc: 0.9418 - val_loss: 0.2887 - val_acc: 0.8982\n",
            "Epoch 71/100\n",
            "1759/1766 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9421WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1635 - acc: 0.9421 - val_loss: 0.3197 - val_acc: 0.8865\n",
            "Epoch 72/100\n",
            "1751/1766 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9421WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1633 - acc: 0.9421 - val_loss: 0.3094 - val_acc: 0.8918\n",
            "Epoch 73/100\n",
            "1751/1766 [============================>.] - ETA: 0s - loss: 0.1629 - acc: 0.9423WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1628 - acc: 0.9424 - val_loss: 0.2930 - val_acc: 0.8987\n",
            "Epoch 74/100\n",
            "1748/1766 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9426WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1622 - acc: 0.9426 - val_loss: 0.2869 - val_acc: 0.8997\n",
            "Epoch 75/100\n",
            "1747/1766 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9430WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1617 - acc: 0.9430 - val_loss: 0.3024 - val_acc: 0.8971\n",
            "Epoch 76/100\n",
            "1754/1766 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9431WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1609 - acc: 0.9430 - val_loss: 0.3039 - val_acc: 0.8929\n",
            "Epoch 77/100\n",
            "1753/1766 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9432WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1610 - acc: 0.9432 - val_loss: 0.2810 - val_acc: 0.8988\n",
            "Epoch 78/100\n",
            "1764/1766 [============================>.] - ETA: 0s - loss: 0.1603 - acc: 0.9432WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 2ms/step - loss: 0.1603 - acc: 0.9432 - val_loss: 0.2900 - val_acc: 0.8992\n",
            "Epoch 79/100\n",
            "1764/1766 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9433WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1599 - acc: 0.9433 - val_loss: 0.2931 - val_acc: 0.8956\n",
            "Epoch 80/100\n",
            "1745/1766 [============================>.] - ETA: 0s - loss: 0.1593 - acc: 0.9438WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1593 - acc: 0.9438 - val_loss: 0.2904 - val_acc: 0.9003\n",
            "Epoch 81/100\n",
            "1754/1766 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9438WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1591 - acc: 0.9438 - val_loss: 0.2972 - val_acc: 0.8972\n",
            "Epoch 82/100\n",
            "1745/1766 [============================>.] - ETA: 0s - loss: 0.1581 - acc: 0.9441WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1582 - acc: 0.9441 - val_loss: 0.2792 - val_acc: 0.9034\n",
            "Epoch 83/100\n",
            "1749/1766 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9439WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1583 - acc: 0.9438 - val_loss: 0.2870 - val_acc: 0.8999\n",
            "Epoch 84/100\n",
            "1752/1766 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9443WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1573 - acc: 0.9443 - val_loss: 0.2886 - val_acc: 0.8997\n",
            "Epoch 85/100\n",
            "1757/1766 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9446WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1573 - acc: 0.9446 - val_loss: 0.3027 - val_acc: 0.8984\n",
            "Epoch 86/100\n",
            "1763/1766 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9445WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1570 - acc: 0.9445 - val_loss: 0.2885 - val_acc: 0.8974\n",
            "Epoch 87/100\n",
            "1749/1766 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9450WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1556 - acc: 0.9450 - val_loss: 0.2822 - val_acc: 0.9014\n",
            "Epoch 88/100\n",
            "1751/1766 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9451WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1557 - acc: 0.9451 - val_loss: 0.2883 - val_acc: 0.9016\n",
            "Epoch 89/100\n",
            "1743/1766 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9454WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1553 - acc: 0.9453 - val_loss: 0.2864 - val_acc: 0.9010\n",
            "Epoch 90/100\n",
            "1763/1766 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9449WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1551 - acc: 0.9450 - val_loss: 0.2784 - val_acc: 0.9019\n",
            "Epoch 91/100\n",
            "1753/1766 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9454WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1546 - acc: 0.9453 - val_loss: 0.2970 - val_acc: 0.8960\n",
            "Epoch 92/100\n",
            "1759/1766 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9457WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1540 - acc: 0.9457 - val_loss: 0.3017 - val_acc: 0.8982\n",
            "Epoch 93/100\n",
            "1764/1766 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9460WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1536 - acc: 0.9460 - val_loss: 0.2928 - val_acc: 0.8996\n",
            "Epoch 94/100\n",
            "1756/1766 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9459WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1531 - acc: 0.9459 - val_loss: 0.2946 - val_acc: 0.8972\n",
            "Epoch 95/100\n",
            "1748/1766 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9461WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1524 - acc: 0.9461 - val_loss: 0.2901 - val_acc: 0.9000\n",
            "Epoch 96/100\n",
            "1766/1766 [==============================] - ETA: 0s - loss: 0.1522 - acc: 0.9463WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1522 - acc: 0.9463 - val_loss: 0.2893 - val_acc: 0.9002\n",
            "Epoch 97/100\n",
            "1756/1766 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9463WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1516 - acc: 0.9463 - val_loss: 0.2955 - val_acc: 0.8979\n",
            "Epoch 98/100\n",
            "1766/1766 [==============================] - ETA: 0s - loss: 0.1512 - acc: 0.9467WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1512 - acc: 0.9467 - val_loss: 0.2860 - val_acc: 0.9013\n",
            "Epoch 99/100\n",
            "1745/1766 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9466WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 5s 3ms/step - loss: 0.1510 - acc: 0.9466 - val_loss: 0.3000 - val_acc: 0.8972\n",
            "Epoch 100/100\n",
            "1761/1766 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9469WARNING:tensorflow:Can save best model only with val_main_acc available, skipping.\n",
            "1766/1766 [==============================] - 4s 3ms/step - loss: 0.1505 - acc: 0.9469 - val_loss: 0.3048 - val_acc: 0.8982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8LxITTsM856"
      },
      "source": [
        "### **Restaurer les poids du modèle sur la meilleure époque d'entraînement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh14_LtSPCqB"
      },
      "source": [
        "### **Prédiction des classes sur le jeu de validation et évaluation en aggrégeant au niveau objet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDpjyx_JPNjv",
        "outputId": "15e106dd-0368-49c7-9b43-c3ed805042c7"
      },
      "source": [
        "# Récupérer les probabilités prédites sur le jeu de validation\n",
        "valid_prob= model.predict(valid_X,batch_size=256)\n",
        "valid_prob.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153469, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26YozrngPZyW",
        "outputId": "d6d0bc8f-8459-43ed-9ee5-9fc8d7d30383"
      },
      "source": [
        "# Retourner la classe correspondant à la probabilité la plus haute\n",
        "valid_pred = np.argmax(valid_prob,axis=1) # axe 1 car ceci concerne chaque ligne\n",
        "valid_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153469,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Fyn2eyWU3w",
        "outputId": "77936af6-110e-4f1a-b4f5-e800f6476784"
      },
      "source": [
        "# Je réencode les prédictions entre 1 et 5\n",
        "valid_pred_enc = encoder.inverse_transform(valid_pred)\n",
        "np.unique(valid_pred_enc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z35nADR_P-ut",
        "outputId": "dfe675a8-5dc4-4444-8a92-6bf940f847ae"
      },
      "source": [
        "# Aggrégation au niveau objet\n",
        "out_pred = []\n",
        "unique_id = np.unique(valid_id)\n",
        "for ID in unique_id :\n",
        "    # Récupérer les prédictions des pixels appartenant au même objet\n",
        "    pred = valid_pred_enc[np.where(valid_id==ID)]\n",
        "    y_true = valid_y[np.where(valid_id==ID)]\n",
        "    # Prendre la valeur majoritaire des prédictions sur les pixels\n",
        "    out_pred.append([ np.bincount(y_true).argmax(), np.bincount(pred).argmax()]) #(Vérité terrain,Prédiction majoritaire)\n",
        "out_pred = np.vstack(out_pred)\n",
        "out_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(558, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ2jDDDZWsKQ",
        "outputId": "84758597-eaaa-4eb6-d022-ffd522242c95"
      },
      "source": [
        "# F1 score au niveau objet\n",
        "f1_score(out_pred[:,0],out_pred[:,1],average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8829109105976405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIXYledyW9QI"
      },
      "source": [
        "### **Prédire sur le jeu test et Préparer une soumission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p--sBOPKW4SE",
        "outputId": "41cca014-bb03-41a2-a21b-6317bfa09df4"
      },
      "source": [
        "# Récupérer les probabilités prédites sur le jeu test\n",
        "test_prob = model.predict(test_X,batch_size=256)\n",
        "test_prob.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(207485, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtI8FHPyXHF1",
        "outputId": "b5e95097-15a7-47ce-afc2-875fe4ecdd48"
      },
      "source": [
        "# Retourner la classe correspondant à la probabilité la plus haute\n",
        "test_pred = np.argmax(test_prob,axis=1) # axe 1 car ceci concerne chaque ligne\n",
        "test_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(207485,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4xPl0mFXNEi",
        "outputId": "c4c792cf-cd9a-468a-91b0-bd9da4e7a6b1"
      },
      "source": [
        "# Je réencode les prédictions entre 1 et 5\n",
        "test_pred_enc = encoder.inverse_transform(test_pred)\n",
        "np.unique(test_pred_enc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khjM1qqMXTSY",
        "outputId": "0416538b-fa4a-4b12-d161-ee71424810fa"
      },
      "source": [
        "# Aggrégation au niveau objet\n",
        "agg_pred = []\n",
        "unique_id = np.unique(test_id)\n",
        "for ID in unique_id :\n",
        "    # Récupérer les prédictions des pixels appartenant au même objet\n",
        "    pred = test_pred_enc[np.where(test_id==ID)]\n",
        "    # Prendre la valeur majoritaire des prédictions sur les pixels\n",
        "    agg_pred.append([ ID, np.bincount(pred).argmax()]) #(ID,Prédiction majoritaire)\n",
        "agg_pred = np.vstack(agg_pred)\n",
        "agg_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZIdn628cEtgx",
        "outputId": "24089fac-5544-443b-c27d-4907ef9b43c8"
      },
      "source": [
        "df = pd.DataFrame({'ID':agg_pred[:,0],'Class':agg_pred[:,1]})\n",
        "df.to_csv('Soumission_ASSARAR_BOUHLEL_DJAFER.csv',index=False)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  Class\n",
              "0   4      5\n",
              "1   7      3\n",
              "2   8      5\n",
              "3   9      3\n",
              "4  10      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6WuuJCkXsu0",
        "outputId": "5817faf0-d193-4095-9bed-c3f7b4e7b918"
      },
      "source": [
        "# F1 Score au niveau objet\n",
        "df_test = pd.read_csv('Test_ID_Label.csv') # Ce fichier vous sera fourni le 12 Novembre\n",
        "f1_score(df_test.Class,df.Class,average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8689058383959432"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWJuC_Mh2rD-"
      },
      "source": [
        "# **Segmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Teu0hQFM2pry",
        "outputId": "55a2a7fd-2deb-438d-fab9-40a11e956654"
      },
      "source": [
        "!ls Images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20160322_S2A.tif  20160730_S2A.tif  20161018_S2A.tif  20161217_S2A.tif\n",
            "20160710_S2A.tif  20160928_S2A.tif  20161127_S2A.tif  20161227_S2A.tif\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}